---
title: 시스템 성능 지표
slug: /test/throughput-latency
tags: [test]
---

### 시스템 성능 지표

시스템 성능은 어떻게 측정할까?  
`성능이 빨라졌다.` 라는 것을 어떻게 수치화할 수 있을까?  
일반적으로 시스템 성능은 Throughput과 Latency라는 성능 지표로 측정을 한다.  

### Throughput

초당 처리하는 작업의 수, 즉 처리량을 의미한다.  
일반적으로 초당 몇 개의 요청을 처리하는지(RPS, Request Per Second)를 기준으로 측정을 한다.  
다음과 같은 시스템이 있다고 가정해보자.

- 시스템 A: 초당 약 100개의 요청 처리
- 시스템 B: 초당 약 200개의 요청 처리

시스템 B가 동시간 대비 더 높은 처리량을 보여주고 있으니, 시스템 B의 성능이 더 좋다고 할 수 있다. 

### Latency

시스템의 평균 응답 시간, 즉 처리 시간을 의미한다.  
Latency는 다음과 같이 두 가지로 구분할 수 있다.  

`사용자가 본 처리 시간`: 사용자가 요청을 보내고 응답을 받을 때까지의 시간  
`시스템에서 본 처리 시간`: 시스템이 요청을 받고 응답을 보낼 때까지의 시간  

사용자가 본 처리 시간의 경우 네트워크에 대한 시간이 포함된다.  
따라서 성능 측정과 개선은 시스템에서 본 처리 시간으로 측정하고 개선하는 것이 더 정확해 보인다.  

다음과 같은 시스템이 있다고 가정해보자.  

- 시스템 A: 요청시 평균 200ms 내 응답  
- 시스템 B: 요청시 평균 100ms 내 응답  

시스템 B가 요청에 대한 응답이 더 빠르니, 시스템 B의 성능이 더 좋다고 할 수 있다.  

### 참고 자료

아마존 웹 서비스 부하 테스트 입문 - 나카가와 타루하치, 모리시타 켄  
[difference between throughput and latency, AWS](https://aws.amazon.com/ko/compare/the-difference-between-throughput-and-latency/) - 해당 내용은 네트워크 기준이다.  